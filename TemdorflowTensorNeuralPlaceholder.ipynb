{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d742c8e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.compat.v1.disable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f4d36377",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b:\n",
      "[[0.6939933  0.32525033]]\n",
      "W:\n",
      "[[-0.17965786  0.513038  ]\n",
      " [-1.1683309  -0.6915931 ]\n",
      " [-1.0279868   0.81512606]]\n",
      "y:\n",
      "[[0.         0.71819735]]\n"
     ]
    }
   ],
   "source": [
    "W = tf.Variable(tf.random_normal([3,2]))\n",
    "b = tf.Variable(tf.random_normal([1,2]))\n",
    "X = tf.placeholder(\"float\",[None,3])#placeholder共2個參數第1個是placeholder的資料型態\n",
    "                                    #第二個參數設定，第1維度設定為None因為傳入的X比數不限數量。第2個維度是每一筆的數字個數。\n",
    "y=tf.nn.relu(tf.matmul(X,W)+b)\n",
    "with tf.Session() as sess:\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "    X_array = np.array([[0.4,0.2,0.4]])\n",
    "    (b,W,X,y) = sess.run((b,W,X,y),feed_dict={X:X_array})\n",
    "    print('b:');print(b)\n",
    "    print('W:');print(W)\n",
    "    print('y:');print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "767995a2",
   "metadata": {},
   "source": [
    "接下來是是3*3的X_array陣列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "028a112d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b:\n",
      "[[0.6544565  0.24483281]]\n",
      "W:\n",
      "[[-0.18009342 -0.28608105]\n",
      " [-0.42683706  0.8954524 ]\n",
      " [-1.077973   -0.84623265]]\n",
      "y:\n",
      "[[0.06586248 0.        ]\n",
      " [0.         0.09407315]\n",
      " [0.23217678 0.        ]]\n"
     ]
    }
   ],
   "source": [
    "W = tf.Variable(tf.random_normal([3,2]))\n",
    "b = tf.Variable(tf.random_normal([1,2]))\n",
    "X = tf.placeholder(\"float\",[None,3])#placeholder共2個參數第1個是placeholder的資料型態\n",
    "                                    #第二個參數設定，第1維度設定為None因為傳入的X比數不限數量。第2個維度是每一筆的數字個數。\n",
    "y=tf.nn.relu(tf.matmul(X,W)+b)\n",
    "with tf.Session() as sess:\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "    X_array = np.array([[0.4,0.2,0.4],\n",
    "                        [0.3,0.4,0.5],\n",
    "                        [0.3,-0.4,0.5]]\n",
    "                       )\n",
    "    (b,W,X,y) = sess.run((b,W,X,y),feed_dict={X:X_array})\n",
    "    print('b:');print(b)\n",
    "    print('W:');print(W)\n",
    "    print('y:');print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b3bf1e5",
   "metadata": {},
   "source": [
    "建立layer函數以矩陣運算模擬神經網路"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d175b352",
   "metadata": {},
   "outputs": [],
   "source": [
    "#out_dim:輸出的神經元數量 input_dim:輸入的神經元數量\n",
    "#inputs:輸入的二微陣列placeholder activation:傳入的激活函數，預設是None\n",
    "def layer(output_dim,input_dim,inputs,activation=None):\n",
    "    #以常態分佈的亂數，建立並且初始值W權重(weight)\n",
    "    #以tf.random_normal函數傳入參數，就可以產生維度是(input_dim,output_dim)的常態分佈的亂數矩陣\n",
    "    W = tf.Variable(tf.random_normal([input_dim,output_dim]))\n",
    "    #以常態分佈的亂數，建立並且b偏差(bias)\n",
    "    #以tf.random_normal函數傳入參數，就可以產生維度是(1,output_dim)的常態分佈的亂數矩陣\n",
    "    b = tf.Variable(tf.random_normal([1,output_dim]))\n",
    "    #建立運算式XWb = (inputs*W)+b\n",
    "    XWb = tf.matmul(inputs,W) + b\n",
    "    #設定激活函數 if None就不要使用激活函數 如果有傳入的話就使用傳入的激活函數進行轉換\n",
    "    if activation is None:\n",
    "        outputs = XWb\n",
    "    else:\n",
    "        outputs = activation(XWb)\n",
    "    return outputs #回傳已建立的神經網路層"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32909c61",
   "metadata": {},
   "source": [
    "使用layer函數建立3層類神經網路"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "95563cd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input Layer X:\n",
      "[[0.4 0.2 0.4 0.5]]\n",
      "hidden Layer h:\n",
      "[[1.6773317 0.        0.7083998]]\n",
      "output Layer y:\n",
      "[[-1.0836902 -3.391754 ]]\n"
     ]
    }
   ],
   "source": [
    "X = tf.placeholder(\"float\",[None,4])\n",
    "#建立隱藏層神經元個數3 x(輸入層)的神經元個數4 傳入x(輸入層)\n",
    "h = layer(output_dim=3,input_dim=4,inputs=X,\n",
    "         activation = tf.nn.relu)\n",
    "#建立輸出層y 建立輸出層神經元個數2 h(隱藏層)的神經元個數3 傳入h(隱藏層)\n",
    "y = layer(output_dim=2,input_dim=3,inputs=h)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "    X_array = np.array([[0.4,0.2,0.4,0.5]])\n",
    "    (layer_X,layer_h,layer_y) = sess.run((X,h,y),feed_dict={X:X_array})\n",
    "    print('input Layer X:');print(layer_X)\n",
    "    print('hidden Layer h:');print(layer_h)\n",
    "    print('output Layer y:');print(layer_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95771a7d",
   "metadata": {},
   "source": [
    "建立layer_debug函數顯示Weight與bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4470e6fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#建立layer_debug\n",
    "def layer_debug(output_dim,input_dim,inputs,activation=None):\n",
    "    W = tf.Variable(tf.random_normal([input_dim,output_dim]))\n",
    "    b = tf.Variable(tf.random_normal([1,output_dim]))\n",
    "    XWb = tf.matmul(inputs,W) + b\n",
    "    if activation is None:\n",
    "        outputs = XWb\n",
    "    else:\n",
    "        outputs = activation(XWb)\n",
    "    return outputs,W,b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "87d3cda9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input Layer X:\n",
      "[[0.4 0.2 0.4 0.5]]\n",
      "W1:\n",
      "[[ 0.53608495  0.2758159   0.44384238]\n",
      " [ 0.06295119 -0.6199612   0.3597841 ]\n",
      " [-1.197828   -0.002801   -1.0461583 ]\n",
      " [ 0.8027972  -1.0089068   0.22693884]]\n",
      "b1:\n",
      "[[ 0.534746   1.8887786 -1.7380314]]\n",
      "hidden Layer h:\n",
      "[[0.68403757 1.3695388  0.        ]]\n",
      "W2:\n",
      "[[-0.5481617   0.17506742]\n",
      " [ 2.068011    0.39338472]\n",
      " [-1.0327802  -0.01912027]]\n",
      "b2:\n",
      "[[0.2425815  0.12189717]]\n",
      "output Layer y:\n",
      "[[2.6998396 0.7804055]]\n"
     ]
    }
   ],
   "source": [
    "#x模擬輸入層，共有4個神經元，輸入的x值是1*4的張量\n",
    "X = tf.placeholder(\"float\",[None,4])\n",
    "#h模擬隱藏層，共有3個神經元，所以是1*3的張量\n",
    "h,W1,b1 = layer_debug(output_dim=3,input_dim=4,inputs=X,activation=tf.nn.relu)\n",
    "#y模擬輸出層，共有2個神經元，所以是1*2的張量\n",
    "y,W2,b2 = layer_debug(output_dim=2,input_dim=3,inputs=h)\n",
    "\n",
    "\n",
    "#W1是權重模擬神經元的軸突，因為輸入層有4個神經元，隱藏層有3個神經元。\n",
    "#為了讓輸入層與隱藏層完全連結，所以W1是4*3的張量\n",
    "\n",
    "#b1是偏差值，模擬突觸的結構，代表接收神經元容易被活化的程度，偏差值越高，越容易被活化並傳遞訊息。\n",
    "#因為隱藏層神經元有3個，所以b1是1*3的張量\n",
    "\n",
    "#W2權重，因為隱藏層有三個神經元，輸出層有2個神經元，為了讓隱藏層與輸出層完全連結，所以W2是3*2的張量\n",
    "\n",
    "#b2是偏差值，因為輸出層神經元有2個，所以b2是1*2的張量\n",
    "\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "    X_array = np.array([[0.4,0.2,0.4,0.5]])\n",
    "    (layer_X,layer_h,layer_y,W1,b1,W2,b2) = sess.run((X,h,y,W1,b1,W2,b2),feed_dict={X:X_array})\n",
    "    print('input Layer X:');print(layer_X)\n",
    "    print('W1:');print(W1)\n",
    "    print('b1:');print(b1)\n",
    "    print('hidden Layer h:');print(layer_h)\n",
    "    print('W2:');print(W2)\n",
    "    print('b2:');print(b2)\n",
    "    print('output Layer y:');print(layer_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7b08539",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
